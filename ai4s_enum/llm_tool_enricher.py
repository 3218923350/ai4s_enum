"""
ä½¿ç”¨ LLM å°†å€™é€‰ repo è½¬æ¢ä¸ºå®Œæ•´çš„å·¥å…·å®šä¹‰
"""
import json
from typing import Dict, List, Optional

from .config import EnumConfig
from .http_utils import safe_request
from .leaf_clusters import LeafCluster
from .logger import get_logger
from .units import Unit

logger = get_logger()


def llm_enrich_tools(
    cfg: EnumConfig,
    *,
    cluster: LeafCluster,
    unit: Unit,
    candidates: List[dict],
    batch_size: int = 10,
) -> List[dict]:
    """
    ä½¿ç”¨ LLM å°†å€™é€‰ repo æ‰¹é‡è½¬æ¢ä¸ºå®Œæ•´çš„å·¥å…·å®šä¹‰ã€‚
    
    è¾“å…¥ candidates æ ¼å¼ï¼ˆæ¥è‡ª GraphQL enrichï¼‰ï¼š
    {
      "full_name": "...",
      "url": "...",
      "description": "...",
      "language": "...",
      "stars": 123,
      "license": "...",
      ...
    }
    
    è¾“å‡º tools æ ¼å¼ï¼š
    {
      "name": "...",
      "one_line_profile": "...",
      "detailed_description": "...",
      "domains": ["B1", "B1-01"],
      "subtask_category": [...],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "...",
      "help_website": [...],
      "license": "...",
      "tags": [...]
    }
    """
    if not cfg.gemini_api_key:
        logger.warning("LLM enrichment æœªå¯ç”¨ | åŸå› =ç¼ºå°‘ GEMINI_API_KEY")
        return []
    
    logger.info(f"å¼€å§‹ LLM æ‰¹é‡enrichment | å€™é€‰æ€»æ•°={len(candidates)}, batch_size={batch_size}")
    tools: List[dict] = []
    
    # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å•æ¬¡ prompt è¿‡é•¿
    for i in range(0, len(candidates), batch_size):
        batch = candidates[i : i + batch_size]
        batch_num = i // batch_size + 1
        total_batches = (len(candidates) + batch_size - 1) // batch_size
        logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} | å€™é€‰={i+1}-{min(i+batch_size, len(candidates))}/{len(candidates)}")
        
        batch_result = _enrich_batch(cfg, cluster=cluster, unit=unit, batch=batch)
        tools.extend(batch_result)
    
    return tools


def _enrich_batch(
    cfg: EnumConfig,
    *,
    cluster: LeafCluster,
    unit: Unit,
    batch: List[dict],
    max_parse_retries: int = 3,
) -> List[dict]:
    """å¤„ç†å•æ‰¹å€™é€‰ï¼Œæ”¯æŒ JSON è§£æå¤±è´¥æ—¶çš„é‡è¯•"""
    
    # æ„å»ºå€™é€‰åˆ—è¡¨çš„ç®€è¦ä¿¡æ¯
    candidates_info = []
    for idx, cand in enumerate(batch):
        candidates_info.append({
            "idx": idx,
            "full_name": cand.get("full_name"),
            "url": cand.get("url"),
            "description": cand.get("description"),
            "language": cand.get("language"),
            "stars": cand.get("stars"),
            "license": cand.get("license"),
        })
    
    prompt = f"""ä½ æ˜¯ AI4Sï¼ˆAI for Scienceï¼‰ç§‘ç ”å·¥å…·ç”Ÿæ€ä¸“å®¶ã€‚

**ä»»åŠ¡**ï¼šä¸¥æ ¼åˆ¤æ–­ä»¥ä¸‹å€™é€‰æ˜¯å¦æ˜¯ã€Œç§‘ç ”å·¥å…·ã€ï¼Œå¹¶ç”Ÿæˆå®Œæ•´å®šä¹‰ã€‚

**å¶å­ç°‡ä¸Šä¸‹æ–‡**ï¼š
- ç°‡ID: {cluster.leaf_cluster_id} - {cluster.leaf_cluster_name}
- é¢†åŸŸ: {cluster.domain}
- å…¸å‹å¯¹è±¡: {cluster.typical_objects}
- å•å…ƒID: {unit.unit_id} - {unit.unit_name}
- è¦†ç›–èŒƒå›´: {unit.coverage_tools}

**å€™é€‰åˆ—è¡¨**ï¼š
```json
{json.dumps(candidates_info, ensure_ascii=False, indent=2)}
```

---

## âš ï¸ ä¸‰æ¡ç¡¬è¿‡æ»¤è§„åˆ™ï¼ˆä¸æ»¡è¶³ä»»ä¸€æ¡ â†’ is_tool=falseï¼‰

### ğŸ§± è§„åˆ™1ï¼šç§‘å­¦ä»»åŠ¡å¯æ˜ å°„æ€§ï¼ˆæœ€é‡è¦ï¼‰
å·¥å…·å¿…é¡»èƒ½ç›´æ¥ç”¨äºä»¥ä¸‹è‡³å°‘ä¸€ç§ç§‘å­¦ä»»åŠ¡ï¼š
- âœ… ç§‘å­¦æ•°æ®ç”Ÿæˆï¼ˆsimulation/synthesisï¼‰
- âœ… ç§‘å­¦æ•°æ®å¤„ç†ï¼ˆalignment/filtering/QC/normalizationï¼‰
- âœ… ç§‘å­¦æ•°æ®åˆ†æï¼ˆinference/estimation/statisticsï¼‰
- âœ… ç§‘å­¦å»ºæ¨¡ï¼ˆphysics/chemistry/biology/materialsï¼‰
- âœ… ç§‘å­¦æ¨æ–­ï¼ˆstructure prediction/dynamics/interactionï¼‰
- âœ… ç§‘å­¦å¯è§†åŒ–ï¼ˆä¸“ç”¨äºç§‘å­¦æ•°æ®ï¼‰

**å…¸å‹åä¾‹ï¼ˆç›´æ¥æ’é™¤ï¼‰**ï¼š
- âŒ é€šç”¨ç¼–ç¨‹åº“ï¼ˆnumpy/pandas é™¤å¤–ï¼‰
- âŒ Webæ¡†æ¶ï¼ˆFastAPI/Flaskç­‰ï¼‰
- âŒ å‰ç«¯ç»„ä»¶ï¼ˆReact/Vueç­‰ï¼‰
- âŒ DevOps/CI/CDå·¥å…·

### ğŸ§± è§„åˆ™2ï¼šæ’é™¤"è½¯ä»¶å·¥ç¨‹å·¥å…·"
å¦‚æœå·¥å…·çš„ä¸»è¦ä»·å€¼æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼Œç›´æ¥æ’é™¤ï¼š
- âŒ Web API æ¡†æ¶/REST æœåŠ¡
- âŒ App UI/å‰ç«¯ç»„ä»¶
- âŒ å¤šåª’ä½“ç¼–è¾‘/æ’­æ”¾å™¨
- âŒ å®‰å…¨æ‰«æ/SAST/æµ‹è¯•æ¡†æ¶
- âŒ DevOps/éƒ¨ç½²/ç›‘æ§

### ğŸ§± è§„åˆ™3ï¼šæ’é™¤"éå·¥å…·å‹ä»“åº“"
- âŒ Papers list / Awesome list / Curated resources
- âŒ æ•™ç¨‹/ç¬”è®°/è¯¾ç¨‹ä½œä¸š
- âŒ çº¯æ–‡æ¡£/README å‹ä»“åº“
- âŒ è®ºæ–‡å¤ç°ä½†æ— å·¥å…·åŒ–æ¥å£
- âŒ ä¸ªäººå­¦ä¹ é¡¹ç›®ï¼ˆstar < 20 ä¸”æ— ç§‘å­¦æœºæ„èƒŒä¹¦ï¼‰

---

## âœ… åˆæ ¼çš„ç§‘ç ”å·¥å…·ç¤ºä¾‹ï¼ˆå¯¹æ ‡ï¼‰
- FastQC, Trimmomatic, Cutadaptï¼ˆç”Ÿä¿¡QCï¼‰
- BWA, STAR, Bowtieï¼ˆåºåˆ—æ¯”å¯¹ï¼‰
- GATK, Picardï¼ˆå˜å¼‚æ£€æµ‹ï¼‰
- STalign, ClipKIT, PhyKITï¼ˆè¿›åŒ–/ç³»ç»Ÿå‘è‚²ï¼‰
- AlphaFold, RoseTTAFoldï¼ˆç»“æ„é¢„æµ‹ï¼‰

---

## è¾“å‡ºæ ¼å¼

**ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„ï¼ˆä¸è¦é¢å¤–æ–‡å­—ï¼‰**ï¼š
```json
[
  {{
    "idx": 0,
    "is_tool": true,
    "name": "FastQC",
    "one_line_profile": "Quality control tool for high throughput sequence data",
    "detailed_description": "...",
    "domains": ["{cluster.leaf_cluster_id}", "{unit.unit_id}"],
    "subtask_category": ["quality_control", "qc_report"],
    "application_level": "solver",
    "primary_language": "Java",
    "repo_url": "...",
    "help_website": [...],
    "license": "GPL-3.0",
    "tags": ["fastq", "quality-control", "ngs"]
  }},
  {{
    "idx": 1,
    "is_tool": false,
    "reason": "é€šç”¨ Web æ¡†æ¶ï¼Œä¸ç¬¦åˆè§„åˆ™1ï¼ˆæ— ç§‘å­¦ä»»åŠ¡æ˜ å°„ï¼‰"
  }},
  {{
    "idx": 2,
    "is_tool": false,
    "reason": "Papers listï¼Œä¸ç¬¦åˆè§„åˆ™3ï¼ˆéå·¥å…·å‹ä»“åº“ï¼‰"
  }}
]
```

**å­—æ®µè¯´æ˜**ï¼š
- application_level: åªèƒ½æ˜¯ library/solver/workflow/platform/dataset/service
- subtask_category: å¿…é¡»æ˜¯ç§‘å­¦ä»»åŠ¡ç›¸å…³ï¼ˆå¦‚ quality_control, alignment, variant_callingï¼‰
- æ‰€æœ‰æè¿°ç”¨è‹±æ–‡

**å…³é”®**ï¼š
1. æ¯ä¸ªå€™é€‰éƒ½å¿…é¡»å‡ºç°ï¼ˆé€šè¿‡ idx å¯¹åº”ï¼‰
2. is_tool=false å¿…é¡»ç»™å‡ºæ˜ç¡® reasonï¼ˆå¼•ç”¨ä¸‰æ¡è§„åˆ™ï¼‰
3. ä¸¥æ ¼æ‰§è¡Œä¸‰æ¡ç¡¬è§„åˆ™ï¼Œ**å®å¯æ¼æ‰è¾¹ç¼˜å·¥å…·ï¼Œä¹Ÿä¸è¦æ··å…¥å™ªå£°**
"""

    # æ”¯æŒ JSON è§£æå¤±è´¥æ—¶çš„é‡è¯•
    for parse_attempt in range(1, max_parse_retries + 1):
        resp = safe_request(
            "POST",
            f"{cfg.gemini_api_base}/chat/completions",
            headers={
                "Authorization": f"Bearer {cfg.gemini_api_key}",
                "Content-Type": "application/json",
            },
            json_data={
                "model": cfg.gemini_model,
                "temperature": 0.1,
                "messages": [{"role": "user", "content": prompt}],
            },
            timeout=6000,
            max_retries=40,
        )

        if resp is None:
            if parse_attempt == max_parse_retries:
                logger.warning(f"LLM enrichment HTTP è¯·æ±‚å¤±è´¥ | æ‰¹æ¬¡å¤§å°={len(batch)}, å·²é‡è¯• {max_parse_retries} æ¬¡")
                return []
            logger.warning(f"LLM enrichment HTTP è¯·æ±‚å¤±è´¥ï¼Œé‡è¯•ä¸­ | attempt={parse_attempt}/{max_parse_retries}")
            continue
        logger.info("resp",resp)
        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if resp.status_code >= 400:
            logger.warning(f"LLM API è¿”å›é”™è¯¯çŠ¶æ€ç  | status={resp.status_code}, attempt={parse_attempt}/{max_parse_retries}")
            if parse_attempt < max_parse_retries:
                continue
            return []

        try:
            # æ£€æŸ¥å“åº”ä½“æ˜¯å¦ä¸ºç©º
            response_text = resp.text
            if not response_text or not response_text.strip():
                logger.warning(f"LLM API è¿”å›ç©ºå“åº” | attempt={parse_attempt}/{max_parse_retries}")
                if parse_attempt < max_parse_retries:
                    continue
                return []

            # å°è¯•è§£æ JSON
            try:
                response_json = resp.json()
            except ValueError as json_err:
                logger.warning(
                    f"LLM API å“åº”ä¸æ˜¯æœ‰æ•ˆ JSON | attempt={parse_attempt}/{max_parse_retries}, "
                    f"error={json_err}, response_preview={response_text[:200]}"
                )
                if parse_attempt < max_parse_retries:
                    continue
                return []

            # æ£€æŸ¥å“åº”ç»“æ„
            if "choices" not in response_json:
                logger.warning(
                    f"LLM API å“åº”ç¼ºå°‘ 'choices' å­—æ®µ | attempt={parse_attempt}/{max_parse_retries}, "
                    f"response_keys={list(response_json.keys())}"
                )
                if parse_attempt < max_parse_retries:
                    continue
                return []

            if not response_json["choices"] or len(response_json["choices"]) == 0:
                logger.warning(f"LLM API å“åº” 'choices' ä¸ºç©º | attempt={parse_attempt}/{max_parse_retries}")
                if parse_attempt < max_parse_retries:
                    continue
                return []

            content = response_json["choices"][0]["message"]["content"]
            print("content",content)
            # å»é™¤å¯èƒ½çš„ markdown ä»£ç å—
            content = content.strip()
            if content.startswith("```"):
                lines = content.split("\n")
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ª ```
                start_idx = 0
                end_idx = len(lines)
                for i, line in enumerate(lines):
                    if line.strip().startswith("```"):
                        if start_idx == 0:
                            start_idx = i + 1
                        else:
                            end_idx = i
                            break
                content = "\n".join(lines[start_idx:end_idx])
            
            # è§£æå†…å®¹ä¸º JSON æ•°ç»„
            results = json.loads(content)
            
            # éªŒè¯ç»“æœæ ¼å¼
            if not isinstance(results, list):
                logger.warning(
                    f"LLM è¿”å›å†…å®¹ä¸æ˜¯ JSON æ•°ç»„ | attempt={parse_attempt}/{max_parse_retries}, "
                    f"type={type(results)}, content_preview={content[:200]}"
                )
                if parse_attempt < max_parse_retries:
                    continue
                return []
            
            # æå– is_tool=true çš„å·¥å…·ï¼Œå¹¶è¡¥å…… id
            tools: List[dict] = []
            for item in results:
                if not isinstance(item, dict):
                    continue
                if item.get("is_tool"):
                    tool = {k: v for k, v in item.items() if k != "idx" and k != "is_tool"}
                    tools.append(tool)
            
            logger.debug(f"æ‰¹æ¬¡è§£ææˆåŠŸ | è¯†åˆ«å·¥å…·æ•°={len(tools)}/{len(batch)}")
            return tools
            
        except json.JSONDecodeError as json_err:
            logger.warning(
                f"LLM å“åº”å†…å®¹ JSON è§£æå¤±è´¥ | attempt={parse_attempt}/{max_parse_retries}, "
                f"error={json_err}, content_preview={content[:200] if 'content' in locals() else 'N/A'}"
            )
            if parse_attempt < max_parse_retries:
                continue
            return []
        except KeyError as key_err:
            logger.warning(
                f"LLM å“åº”ç»“æ„å¼‚å¸¸ | attempt={parse_attempt}/{max_parse_retries}, "
                f"missing_key={key_err}, response_keys={list(response_json.keys()) if 'response_json' in locals() else 'N/A'}"
            )
            if parse_attempt < max_parse_retries:
                continue
            return []
        except Exception as e:
            logger.warning(
                f"LLM enrichment å“åº”è§£æå¤±è´¥ | attempt={parse_attempt}/{max_parse_retries}, "
                f"error={e}, error_type={type(e).__name__}"
            )
            if parse_attempt < max_parse_retries:
                continue
            return []
    
    return []

