"""
ä½¿ç”¨ LLM å°†å€™é€‰ repo è½¬æ¢ä¸ºå®Œæ•´çš„å·¥å…·å®šä¹‰
"""
import json
import time
from typing import Dict, List, Optional

from .config import EnumConfig
from .http_utils import safe_request
from .leaf_clusters import LeafCluster
from .logger import get_logger
from .units import Unit

logger = get_logger()


def llm_enrich_tools(
    cfg: EnumConfig,
    *,
    cluster: LeafCluster,
    unit: Unit,
    candidates: List[dict],
    batch_size: int = 10,
) -> List[dict]:
    """
    ä½¿ç”¨ LLM å°†å€™é€‰ repo æ‰¹é‡è½¬æ¢ä¸ºå®Œæ•´çš„å·¥å…·å®šä¹‰ã€‚
    
    è¾“å…¥ candidates æ ¼å¼ï¼ˆæ¥è‡ª GraphQL enrichï¼‰ï¼š
    {
      "full_name": "...",
      "url": "...",
      "description": "...",
      "language": "...",
      "stars": 123,
      "license": "...",
      ...
    }
    
    è¾“å‡º tools æ ¼å¼ï¼š
    {
      "name": "...",
      "one_line_profile": "...",
      "detailed_description": "...",
      "domains": ["B1", "B1-01"],
      "subtask_category": [...],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "...",
      "help_website": [...],
      "license": "...",
      "tags": [...]
    }
    """
    if not cfg.gemini_api_key:
        logger.warning("LLM enrichment æœªå¯ç”¨ | åŸå› =ç¼ºå°‘ GEMINI_API_KEY")
        return []
    
    logger.info(f"å¼€å§‹ LLM æ‰¹é‡enrichment | å€™é€‰æ€»æ•°={len(candidates)}, batch_size={batch_size}")
    tools: List[dict] = []
    
    # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å•æ¬¡ prompt è¿‡é•¿
    for i in range(0, len(candidates), batch_size):
        batch = candidates[i : i + batch_size]
        batch_num = i // batch_size + 1
        total_batches = (len(candidates) + batch_size - 1) // batch_size
        logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} | å€™é€‰={i+1}-{min(i+batch_size, len(candidates))}/{len(candidates)}")
        
        batch_result = _enrich_batch(cfg, cluster=cluster, unit=unit, batch=batch)
        tools.extend(batch_result)
    
    return tools


def _enrich_batch(
    cfg: EnumConfig,
    *,
    cluster: LeafCluster,
    unit: Unit,
    batch: List[dict],
    max_parse_retries: int = 3,
) -> List[dict]:
    """å¤„ç†å•æ‰¹å€™é€‰ï¼Œæ”¯æŒ JSON è§£æå¤±è´¥æ—¶çš„é‡è¯•"""
    
    # æ„å»ºå€™é€‰åˆ—è¡¨çš„ç®€è¦ä¿¡æ¯
    candidates_info = []
    for idx, cand in enumerate(batch):
        candidates_info.append({
            "idx": idx,
            "full_name": cand.get("full_name"),
            "url": cand.get("url"),
            "description": cand.get("description"),
            "language": cand.get("language"),
            "stars": cand.get("stars"),
            "license": cand.get("license"),
        })
    
    prompt = f"""ä½ æ˜¯ AI4Sï¼ˆAI for Scienceï¼‰ç§‘ç ”å·¥å…·ç”Ÿæ€ä¸“å®¶ã€‚

**ä»»åŠ¡**ï¼šä¸¥æ ¼åˆ¤æ–­ä»¥ä¸‹å€™é€‰æ˜¯å¦æ˜¯ã€Œç§‘ç ”å·¥å…·ã€ï¼Œå¹¶ç”Ÿæˆå®Œæ•´å®šä¹‰ã€‚

**å¶å­ç°‡ä¸Šä¸‹æ–‡**ï¼š
- ç°‡ID: {cluster.leaf_cluster_id} - {cluster.leaf_cluster_name}
- é¢†åŸŸ: {cluster.domain}
- å…¸å‹å¯¹è±¡: {cluster.typical_objects}
- å•å…ƒID: {unit.unit_id} - {unit.unit_name}
- è¦†ç›–èŒƒå›´: {unit.coverage_tools}

**å€™é€‰åˆ—è¡¨**ï¼š
```json
{json.dumps(candidates_info, ensure_ascii=False, indent=2)}
```

---

## âš ï¸ ä¸‰æ¡ç¡¬è¿‡æ»¤è§„åˆ™ï¼ˆä¸æ»¡è¶³ä»»ä¸€æ¡ â†’ is_tool=falseï¼‰

### ğŸ§± è§„åˆ™1ï¼šç§‘å­¦ä»»åŠ¡å¯æ˜ å°„æ€§ï¼ˆæœ€é‡è¦ï¼‰
å·¥å…·å¿…é¡»èƒ½ç›´æ¥ç”¨äºä»¥ä¸‹è‡³å°‘ä¸€ç§ç§‘å­¦ä»»åŠ¡ï¼š
- âœ… ç§‘å­¦æ•°æ®ç”Ÿæˆï¼ˆsimulation/synthesisï¼‰
- âœ… ç§‘å­¦æ•°æ®å¤„ç†ï¼ˆalignment/filtering/QC/normalizationï¼‰
- âœ… ç§‘å­¦æ•°æ®åˆ†æï¼ˆinference/estimation/statisticsï¼‰
- âœ… ç§‘å­¦å»ºæ¨¡ï¼ˆphysics/chemistry/biology/materialsï¼‰
- âœ… ç§‘å­¦æ¨æ–­ï¼ˆstructure prediction/dynamics/interactionï¼‰
- âœ… ç§‘å­¦å¯è§†åŒ–ï¼ˆä¸“ç”¨äºç§‘å­¦æ•°æ®ï¼‰

**å…¸å‹åä¾‹ï¼ˆç›´æ¥æ’é™¤ï¼‰**ï¼š
- âŒ é€šç”¨ç¼–ç¨‹åº“ï¼ˆnumpy/pandas é™¤å¤–ï¼‰
- âŒ Webæ¡†æ¶ï¼ˆFastAPI/Flaskç­‰ï¼‰
- âŒ å‰ç«¯ç»„ä»¶ï¼ˆReact/Vueç­‰ï¼‰
- âŒ DevOps/CI/CDå·¥å…·

### ğŸ§± è§„åˆ™2ï¼šæ’é™¤"è½¯ä»¶å·¥ç¨‹å·¥å…·"
å¦‚æœå·¥å…·çš„ä¸»è¦ä»·å€¼æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼Œç›´æ¥æ’é™¤ï¼š
- âŒ Web API æ¡†æ¶/REST æœåŠ¡
- âŒ App UI/å‰ç«¯ç»„ä»¶
- âŒ å¤šåª’ä½“ç¼–è¾‘/æ’­æ”¾å™¨
- âŒ å®‰å…¨æ‰«æ/SAST/æµ‹è¯•æ¡†æ¶
- âŒ DevOps/éƒ¨ç½²/ç›‘æ§

### ğŸ§± è§„åˆ™3ï¼šæ’é™¤"éå·¥å…·å‹ä»“åº“"
- âŒ Papers list / Awesome list / Curated resources
- âŒ æ•™ç¨‹/ç¬”è®°/è¯¾ç¨‹ä½œä¸š
- âŒ çº¯æ–‡æ¡£/README å‹ä»“åº“
- âŒ è®ºæ–‡å¤ç°ä½†æ— å·¥å…·åŒ–æ¥å£
- âŒ ä¸ªäººå­¦ä¹ é¡¹ç›®ï¼ˆstar < 20 ä¸”æ— ç§‘å­¦æœºæ„èƒŒä¹¦ï¼‰

---

## âœ… åˆæ ¼çš„ç§‘ç ”å·¥å…·ç¤ºä¾‹ï¼ˆå¯¹æ ‡ï¼‰
- FastQC, Trimmomatic, Cutadaptï¼ˆç”Ÿä¿¡QCï¼‰
- BWA, STAR, Bowtieï¼ˆåºåˆ—æ¯”å¯¹ï¼‰
- GATK, Picardï¼ˆå˜å¼‚æ£€æµ‹ï¼‰
- STalign, ClipKIT, PhyKITï¼ˆè¿›åŒ–/ç³»ç»Ÿå‘è‚²ï¼‰
- AlphaFold, RoseTTAFoldï¼ˆç»“æ„é¢„æµ‹ï¼‰

---

## è¾“å‡ºæ ¼å¼

**ä¸¥æ ¼è¾“å‡º JSON å¯¹è±¡ï¼ˆå¿…é¡»åŒ…å« "results" å­—æ®µï¼Œå€¼ä¸ºæ•°ç»„ï¼Œä¸è¦é¢å¤–æ–‡å­—ï¼‰**ï¼š
```json
{{
  "results": [
    {{
      "idx": 0,
      "is_tool": true,
      "name": "FastQC",
      "one_line_profile": "Quality control tool for high throughput sequence data",
      "detailed_description": "...",
      "domains": ["{cluster.leaf_cluster_id}", "{unit.unit_id}"],
      "subtask_category": ["quality_control", "qc_report"],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "...",
      "help_website": [...],
      "license": "GPL-3.0",
      "tags": ["fastq", "quality-control", "ngs"]
    }},
    {{
      "idx": 1,
      "is_tool": false,
      "reason": "é€šç”¨ Web æ¡†æ¶ï¼Œä¸ç¬¦åˆè§„åˆ™1ï¼ˆæ— ç§‘å­¦ä»»åŠ¡æ˜ å°„ï¼‰"
    }},
    {{
      "idx": 2,
      "is_tool": false,
      "reason": "Papers listï¼Œä¸ç¬¦åˆè§„åˆ™3ï¼ˆéå·¥å…·å‹ä»“åº“ï¼‰"
    }}
  ]
}}
```

**å­—æ®µè¯´æ˜**ï¼š
- application_level: åªèƒ½æ˜¯ library/solver/workflow/platform/dataset/service
- subtask_category: å¿…é¡»æ˜¯ç§‘å­¦ä»»åŠ¡ç›¸å…³ï¼ˆå¦‚ quality_control, alignment, variant_callingï¼‰
- æ‰€æœ‰æè¿°ç”¨è‹±æ–‡

**å…³é”®**ï¼š
1. å¿…é¡»è¾“å‡ºæœ‰æ•ˆçš„ JSON å¯¹è±¡ï¼ŒåŒ…å« "results" å­—æ®µ
2. "results" å¿…é¡»æ˜¯æ•°ç»„ï¼Œæ¯ä¸ªå€™é€‰éƒ½å¿…é¡»å‡ºç°ï¼ˆé€šè¿‡ idx å¯¹åº”ï¼‰
3. is_tool=false å¿…é¡»ç»™å‡ºæ˜ç¡® reasonï¼ˆå¼•ç”¨ä¸‰æ¡è§„åˆ™ï¼‰
4. ä¸¥æ ¼æ‰§è¡Œä¸‰æ¡ç¡¬è§„åˆ™ï¼Œ**å®å¯æ¼æ‰è¾¹ç¼˜å·¥å…·ï¼Œä¹Ÿä¸è¦æ··å…¥å™ªå£°**
"""

    # å°è¯•ä½¿ç”¨ OpenAI SDKï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œå¦åˆ™å›é€€åˆ° HTTP è¯·æ±‚
    try:
        from openai import OpenAI
        
        client = OpenAI(
            api_key=cfg.gemini_api_key,
            base_url=cfg.gemini_api_base,
            timeout=600.0,
        )
        
        # ä½¿ç”¨ OpenAI SDK å¹¶å¼ºåˆ¶ JSON è¾“å‡º
        for parse_attempt in range(1, max_parse_retries + 1):
            try:
                # å°è¯•ä¸ä½¿ç”¨ response_formatï¼Œå› ä¸ºå¯èƒ½ä¸è¢«æ”¯æŒæˆ–å¯¼è‡´ç©ºå“åº”
                # å¦‚æœ API æ”¯æŒï¼Œä¼šåœ¨ prompt ä¸­è¦æ±‚ JSON è¾“å‡º
                response = client.chat.completions.create(
                    model=cfg.gemini_model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1,
                    timeout=600.0,
                )
                
                # æå–å†…å®¹
                if not response.choices or len(response.choices) == 0:
                    logger.warning(f"LLM API å“åº” 'choices' ä¸ºç©º | attempt={parse_attempt}/{max_parse_retries}")
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)  # æŒ‡æ•°é€€é¿
                        continue
                    return []
                
                choice = response.choices[0]
                # æ£€æŸ¥ finish_reasonï¼Œå¯èƒ½æ˜¯ "stop", "length", "content_filter" ç­‰
                finish_reason = getattr(choice, 'finish_reason', None)
                if finish_reason and finish_reason != "stop":
                    logger.warning(
                        f"LLM API å“åº” finish_reason å¼‚å¸¸ | attempt={parse_attempt}/{max_parse_retries}, "
                        f"finish_reason={finish_reason}, response_id={getattr(response, 'id', 'N/A')}"
                    )
                
                content = choice.message.content
                if content is None:
                    logger.warning(
                        f"LLM API è¿”å› content=None | attempt={parse_attempt}/{max_parse_retries}, "
                        f"finish_reason={finish_reason}, response_id={getattr(response, 'id', 'N/A')}, "
                        f"message_keys={list(choice.message.__dict__.keys()) if hasattr(choice.message, '__dict__') else 'N/A'}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []
                
                if not content or not content.strip():
                    logger.warning(
                        f"LLM API è¿”å›ç©º content | attempt={parse_attempt}/{max_parse_retries}, "
                        f"finish_reason={finish_reason}, response_id={getattr(response, 'id', 'N/A')}, "
                        f"content_type={type(content)}, content_repr={repr(content)[:100]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []
                
                # å»é™¤å¯èƒ½çš„ markdown ä»£ç å—
                content = content.strip()
                original_content = content  # ä¿å­˜åŸå§‹å†…å®¹ç”¨äºè°ƒè¯•
                
                if content.startswith("```"):
                    lines = content.split("\n")
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ª ```
                    start_idx = None
                    end_idx = len(lines)
                    for i, line in enumerate(lines):
                        if line.strip().startswith("```"):
                            if start_idx is None:
                                start_idx = i + 1
                            else:
                                end_idx = i
                                break
                    
                    if start_idx is not None:
                        content = "\n".join(lines[start_idx:end_idx]).strip()
                    else:
                        # å¦‚æœåªæœ‰å¼€å§‹çš„ ```ï¼Œæ²¡æœ‰ç»“æŸçš„ï¼Œå°è¯•å»é™¤ç¬¬ä¸€è¡Œ
                        if len(lines) > 1:
                            content = "\n".join(lines[1:]).strip()
                
                # å¦‚æœå»é™¤ä»£ç å—åä»ç„¶ä»¥ ``` å¼€å¤´ï¼Œå°è¯•æ›´æ¿€è¿›çš„æ¸…ç†
                if content.startswith("```"):
                    # å¯èƒ½æ˜¯åµŒå¥—çš„ä»£ç å—æ ‡è®°ï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªé ``` çš„è¡Œ
                    lines = content.split("\n")
                    for i, line in enumerate(lines):
                        if not line.strip().startswith("```"):
                            content = "\n".join(lines[i:]).strip()
                            break
                
                try:
                    # å°è¯•è§£æä¸º JSON å¯¹è±¡ï¼Œç„¶åæ£€æŸ¥æ˜¯å¦æœ‰æ•°ç»„å­—æ®µ
                    parsed = json.loads(content)
                    
                    # å¦‚æœç›´æ¥æ˜¯æ•°ç»„ï¼Œä½¿ç”¨å®ƒ
                    if isinstance(parsed, list):
                        results = parsed
                    # å¦‚æœæ˜¯å¯¹è±¡ï¼Œä¼˜å…ˆæŸ¥æ‰¾ "results" å­—æ®µï¼Œå¦åˆ™æŸ¥æ‰¾ä»»ä½•æ•°ç»„å­—æ®µ
                    elif isinstance(parsed, dict):
                        # ä¼˜å…ˆæŸ¥æ‰¾ "results" å­—æ®µ
                        if "results" in parsed and isinstance(parsed["results"], list):
                            results = parsed["results"]
                        else:
                            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæ•°ç»„ç±»å‹çš„å€¼
                            results = None
                            for key, value in parsed.items():
                                if isinstance(value, list):
                                    results = value
                                    break
                            if results is None:
                                logger.warning(
                                    f"LLM è¿”å› JSON å¯¹è±¡ä½†æ— æ•°ç»„å­—æ®µ | attempt={parse_attempt}/{max_parse_retries}, "
                                    f"keys={list(parsed.keys())}, content_preview={content[:200]}"
                                )
                                if parse_attempt < max_parse_retries:
                                    time.sleep(2 ** parse_attempt)
                                    continue
                                return []
                    else:
                        logger.warning(
                            f"LLM è¿”å›å†…å®¹ä¸æ˜¯æ•°ç»„æˆ–å¯¹è±¡ | attempt={parse_attempt}/{max_parse_retries}, "
                            f"type={type(parsed)}, content_preview={content[:200]}"
                        )
                        if parse_attempt < max_parse_retries:
                            time.sleep(2 ** parse_attempt)
                            continue
                        return []
                    
                    # éªŒè¯ç»“æœæ ¼å¼
                    if not isinstance(results, list):
                        logger.warning(
                            f"LLM è¿”å›å†…å®¹ä¸æ˜¯ JSON æ•°ç»„ | attempt={parse_attempt}/{max_parse_retries}, "
                            f"type={type(results)}, content_preview={content[:200]}"
                        )
                        if parse_attempt < max_parse_retries:
                            time.sleep(2 ** parse_attempt)
                            continue
                        return []
                    
                    # æå– is_tool=true çš„å·¥å…·
                    tools: List[dict] = []
                    for item in results:
                        if not isinstance(item, dict):
                            continue
                        if item.get("is_tool"):
                            tool = {k: v for k, v in item.items() if k != "idx" and k != "is_tool"}
                            tools.append(tool)
                    
                    logger.debug(f"æ‰¹æ¬¡è§£ææˆåŠŸ | è¯†åˆ«å·¥å…·æ•°={len(tools)}/{len(batch)}")
                    return tools
                    
                except json.JSONDecodeError as json_err:
                    logger.warning(
                        f"LLM å“åº”å†…å®¹ JSON è§£æå¤±è´¥ | attempt={parse_attempt}/{max_parse_retries}, "
                        f"error={json_err}, content_preview={content[:200]}, "
                        f"original_preview={original_content[:200] if 'original_content' in locals() else 'N/A'}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []
                    
            except Exception as e:
                logger.warning(
                    f"LLM enrichment è¯·æ±‚å¤±è´¥ | attempt={parse_attempt}/{max_parse_retries}, "
                    f"error={e}, error_type={type(e).__name__}"
                )
                if parse_attempt < max_parse_retries:
                    time.sleep(2 ** parse_attempt)
                    continue
                return []
        
        return []
        
    except ImportError:
        # å›é€€åˆ° HTTP è¯·æ±‚æ–¹å¼
        logger.debug("OpenAI SDK æœªå®‰è£…ï¼Œä½¿ç”¨ HTTP è¯·æ±‚æ–¹å¼")
        
        # æ”¯æŒ JSON è§£æå¤±è´¥æ—¶çš„é‡è¯•
        for parse_attempt in range(1, max_parse_retries + 1):
            resp = safe_request(
                "POST",
                f"{cfg.gemini_api_base}/chat/completions",
                headers={
                    "Authorization": f"Bearer {cfg.gemini_api_key}",
                    "Content-Type": "application/json",
                },
                json_data={
                    "model": cfg.gemini_model,
                    "temperature": 0.1,
                    "messages": [{"role": "user", "content": prompt}],
                    # ä¸ä½¿ç”¨ response_formatï¼Œä¸ llm_query_generator.py ä¿æŒä¸€è‡´
                },
                timeout=6000,
                max_retries=40,
            )

            if resp is None:
                if parse_attempt == max_parse_retries:
                    logger.warning(f"LLM enrichment HTTP è¯·æ±‚å¤±è´¥ | æ‰¹æ¬¡å¤§å°={len(batch)}, å·²é‡è¯• {max_parse_retries} æ¬¡")
                    return []
                logger.warning(f"LLM enrichment HTTP è¯·æ±‚å¤±è´¥ï¼Œé‡è¯•ä¸­ | attempt={parse_attempt}/{max_parse_retries}")
                time.sleep(2 ** parse_attempt)
                continue

            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
            if resp.status_code >= 400:
                logger.warning(
                    f"LLM API è¿”å›é”™è¯¯çŠ¶æ€ç  | status={resp.status_code}, "
                    f"response_text={resp.text[:200]}, attempt={parse_attempt}/{max_parse_retries}"
                )
                if parse_attempt < max_parse_retries:
                    time.sleep(2 ** parse_attempt)
                    continue
                return []

            try:
                # æ£€æŸ¥å“åº”ä½“æ˜¯å¦ä¸ºç©º
                response_text = resp.text
                if not response_text or not response_text.strip():
                    logger.warning(f"LLM API è¿”å›ç©ºå“åº” | attempt={parse_attempt}/{max_parse_retries}")
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []

                # å°è¯•è§£æ JSON
                try:
                    response_json = resp.json()
                except ValueError as json_err:
                    logger.warning(
                        f"LLM API å“åº”ä¸æ˜¯æœ‰æ•ˆ JSON | attempt={parse_attempt}/{max_parse_retries}, "
                        f"error={json_err}, response_preview={response_text[:200]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []

                # æ£€æŸ¥å“åº”ç»“æ„
                if "choices" not in response_json:
                    logger.warning(
                        f"LLM API å“åº”ç¼ºå°‘ 'choices' å­—æ®µ | attempt={parse_attempt}/{max_parse_retries}, "
                        f"response_keys={list(response_json.keys())}, response_preview={json.dumps(response_json, ensure_ascii=False)[:500]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []

                if not response_json["choices"] or len(response_json["choices"]) == 0:
                    logger.warning(
                        f"LLM API å“åº” 'choices' ä¸ºç©º | attempt={parse_attempt}/{max_parse_retries}, "
                        f"full_response={json.dumps(response_json, ensure_ascii=False)[:500]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []

                # æ£€æŸ¥ message ç»“æ„
                message = response_json["choices"][0].get("message")
                if not message:
                    logger.warning(
                        f"LLM API å“åº”ç¼ºå°‘ 'message' å­—æ®µ | attempt={parse_attempt}/{max_parse_retries}, "
                        f"choice_keys={list(response_json['choices'][0].keys())}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []

                content = message.get("content")
                if content is None:
                    logger.warning(
                        f"LLM API å“åº” 'content' ä¸º None | attempt={parse_attempt}/{max_parse_retries}, "
                        f"message_keys={list(message.keys())}, full_response={json.dumps(response_json, ensure_ascii=False)[:500]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []
                
                if not content or not content.strip():
                    logger.warning(
                        f"LLM API è¿”å›ç©º content | attempt={parse_attempt}/{max_parse_retries}, "
                        f"content_type={type(content)}, content_repr={repr(content)[:100]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []

                # å»é™¤å¯èƒ½çš„ markdown ä»£ç å—
                content = content.strip()
                if content.startswith("```"):
                    lines = content.split("\n")
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ª ```
                    start_idx = 0
                    end_idx = len(lines)
                    for i, line in enumerate(lines):
                        if line.strip().startswith("```"):
                            if start_idx == 0:
                                start_idx = i + 1
                            else:
                                end_idx = i
                                break
                    content = "\n".join(lines[start_idx:end_idx])
                
                # è§£æå†…å®¹ä¸º JSON
                try:
                    parsed = json.loads(content)
                    
                    # å¦‚æœç›´æ¥æ˜¯æ•°ç»„ï¼Œä½¿ç”¨å®ƒ
                    if isinstance(parsed, list):
                        results = parsed
                    # å¦‚æœæ˜¯å¯¹è±¡ï¼Œä¼˜å…ˆæŸ¥æ‰¾ "results" å­—æ®µï¼Œå¦åˆ™æŸ¥æ‰¾ä»»ä½•æ•°ç»„å­—æ®µ
                    elif isinstance(parsed, dict):
                        # ä¼˜å…ˆæŸ¥æ‰¾ "results" å­—æ®µ
                        if "results" in parsed and isinstance(parsed["results"], list):
                            results = parsed["results"]
                        else:
                            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæ•°ç»„ç±»å‹çš„å€¼
                            results = None
                            for key, value in parsed.items():
                                if isinstance(value, list):
                                    results = value
                                    break
                            if results is None:
                                logger.warning(
                                    f"LLM è¿”å› JSON å¯¹è±¡ä½†æ— æ•°ç»„å­—æ®µ | attempt={parse_attempt}/{max_parse_retries}, "
                                    f"keys={list(parsed.keys())}, content_preview={content[:200]}"
                                )
                                if parse_attempt < max_parse_retries:
                                    time.sleep(2 ** parse_attempt)
                                    continue
                                return []
                    else:
                        logger.warning(
                            f"LLM è¿”å›å†…å®¹ä¸æ˜¯æ•°ç»„æˆ–å¯¹è±¡ | attempt={parse_attempt}/{max_parse_retries}, "
                            f"type={type(parsed)}, content_preview={content[:200]}"
                        )
                        if parse_attempt < max_parse_retries:
                            time.sleep(2 ** parse_attempt)
                            continue
                        return []
                    
                except json.JSONDecodeError as json_err:
                    logger.warning(
                        f"LLM å“åº”å†…å®¹ JSON è§£æå¤±è´¥ | attempt={parse_attempt}/{max_parse_retries}, "
                        f"error={json_err}, content_preview={content[:200]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []
                
                # éªŒè¯ç»“æœæ ¼å¼
                if not isinstance(results, list):
                    logger.warning(
                        f"LLM è¿”å›å†…å®¹ä¸æ˜¯ JSON æ•°ç»„ | attempt={parse_attempt}/{max_parse_retries}, "
                        f"type={type(results)}, content_preview={content[:200]}"
                    )
                    if parse_attempt < max_parse_retries:
                        time.sleep(2 ** parse_attempt)
                        continue
                    return []
                
                # æå– is_tool=true çš„å·¥å…·
                tools: List[dict] = []
                for item in results:
                    if not isinstance(item, dict):
                        continue
                    if item.get("is_tool"):
                        tool = {k: v for k, v in item.items() if k != "idx" and k != "is_tool"}
                        tools.append(tool)
                
                logger.debug(f"æ‰¹æ¬¡è§£ææˆåŠŸ | è¯†åˆ«å·¥å…·æ•°={len(tools)}/{len(batch)}")
                return tools
                
            except KeyError as key_err:
                logger.warning(
                    f"LLM å“åº”ç»“æ„å¼‚å¸¸ | attempt={parse_attempt}/{max_parse_retries}, "
                    f"missing_key={key_err}, response_keys={list(response_json.keys()) if 'response_json' in locals() else 'N/A'}"
                )
                if parse_attempt < max_parse_retries:
                    time.sleep(2 ** parse_attempt)
                    continue
                return []
            except Exception as e:
                logger.warning(
                    f"LLM enrichment å“åº”è§£æå¤±è´¥ | attempt={parse_attempt}/{max_parse_retries}, "
                    f"error={e}, error_type={type(e).__name__}"
                )
                if parse_attempt < max_parse_retries:
                    time.sleep(2 ** parse_attempt)
                    continue
                return []
        
        return []

